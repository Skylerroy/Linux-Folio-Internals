\documentclass[../main.tex]{subfiles}
\begin{document}
\chapter{folio与页缓存}
\label{chap:folio-page-cache}

\begin{epigraph}
\textit{``The page cache is the heart of Linux's memory management. Everything else is just plumbing.''}
\begin{flushright}
--- Linux Kernel Developer
\end{flushright}
\end{epigraph}

\section{引言}

页缓存（Page Cache）是Linux内核内存管理的核心组件之一，负责缓存文件系统数据以提高I/O性能。在folio引入之前，页缓存基于\texttt{struct page}实现，存在诸多设计上的局限性。folio的出现为页缓存带来了革命性的改进。

本章将深入探讨folio如何重新定义页缓存的实现，包括：
\begin{itemize}
    \item 传统页缓存的局限性分析
    \item folio如何解决这些局限性
    \item folio页缓存的核心数据结构
    \item 文件读写操作的folio化改造
    \item 页缓存管理算法的优化
    \item 性能对比和基准测试
    \item 实际应用场景分析
\end{itemize}

\section{传统页缓存的局限性}

\subsection{复合页处理的复杂性}

在传统页缓存中，处理复合页（Compound Pages）是一个复杂且容易出错的过程：

\begin{lstlisting}[language=C,caption={传统复合页处理复杂性示例},label={lst:traditional-compound-complexity}]
/* 传统方式：需要频繁的头页检查 */
static int page_cache_read_pages(struct address_space *mapping,
                               struct list_head *pages,
                               unsigned nr_pages)
{
    struct page *page;
    struct page *head;
    int ret = 0;
    
    list_for_each_entry(page, pages, lru) {
        /* 关键问题：每次都需要获取头页 */
        head = compound_head(page);
        
        /* 检查是否是复合页 */
        if (PageCompound(head)) {
            /* 复杂的复合页处理逻辑 */
            unsigned int nr = compound_nr(head);
            unsigned int offset = page - head;
            
            /* 需要特殊处理复合页的不同部分 */
            if (offset == 0) {
                /* 处理复合页头 */
                ret = handle_compound_head(head, nr);
            } else {
                /* 处理复合页尾部 */
                ret = handle_compound_tail(page, offset);
            }
        } else {
            /* 普通单页处理 */
            ret = handle_single_page(page);
        }
        
        if (ret)
            break;
    }
    
    return ret;
}
\end{lstlisting}

上述代码展示了传统页缓存中处理复合页的典型模式。函数\texttt{page\_cache\_read\_pages}接收一个\texttt{address\_space}映射、一个页链表以及页的数量作为参数。在遍历页链表时，每次迭代都必须调用\texttt{compound\_head()}来获取复合页的头页，这是一个额外的间接操作。随后通过\texttt{PageCompound()}判断当前页是否属于复合页，如果是，则需要计算页面在复合页中的偏移量（\texttt{page - head}），并根据偏移量是否为零来区分头页和尾页，分别调用不同的处理函数。

这种设计的核心问题在于：开发者必须时刻意识到当前操作的\texttt{struct page}可能是复合页的一部分，并在每个操作点进行头页检查和类型判断。这不仅增加了代码的复杂度，还容易在某些路径上遗漏检查，导致难以调试的内核错误。folio通过将复合页的概念直接内建到类型系统中，从根本上消除了这种复杂性。

\subsection{类型安全问题}

传统页缓存API缺乏类型安全检查，容易导致运行时错误：

\begin{lstlisting}[language=C,caption={类型安全问题示例},label={lst:type-safety-issues}]
/* 危险的类型转换 */
void dangerous_page_operation(struct page *page)
{
    /* 假设page可能是指向folio的指针 */
    struct folio *folio = (struct folio *)page;  /* 危险转换 */
    
    /* 如果page不是folio，这里会访问非法内存 */
    folio_lock(folio);  /* 可能导致内核崩溃 */
}

/* 更安全但冗长的检查 */
void safe_page_operation(struct page *page)
{
    if (is_folio_address(page)) {
        struct folio *folio = page_folio(page);
        folio_lock(folio);
        /* folio操作 */
        folio_unlock(folio);
    } else {
        lock_page(page);
        /* page操作 */
        unlock_page(page);
    }
}
\end{lstlisting}

代码中展示了两种处理\texttt{struct page}的方式。第一个函数\texttt{dangerous\_page\_operation}直接将\texttt{struct page}指针强制转换为\texttt{struct folio}指针，这是一种极其危险的操作——如果传入的\texttt{page}并非folio（即不是复合页的头页或独立页），后续对\texttt{folio\_lock()}的调用将访问非法内存区域，可能导致内核崩溃或数据损坏。

第二个函数\texttt{safe\_page\_operation}展示了更安全但冗长的做法：先通过\texttt{is\_folio\_address()}检查页面是否是folio，然后根据检查结果走不同的代码路径。folio路径使用\texttt{page\_folio()}进行安全转换并调用\texttt{folio\_lock()}/\texttt{folio\_unlock()}，而非folio路径则使用传统的\texttt{lock\_page()}/\texttt{unlock\_page()}。这种模式虽然安全，但需要在每个操作点都编写双重路径代码，增加了维护负担。folio API的引入正是为了消除这种二元性，让所有页缓存操作统一使用folio接口。

\subsection{内存管理开销}

传统页缓存存在不必要的内存管理开销：

\begin{lstlisting}[language=C,caption={内存管理开销示例},label={lst:memory-overhead}]
/* 传统页缓存的内存布局问题 */
struct page_cache_analysis {
    /* 每个page结构体都有完整的字段 */
    struct page page1;  /* 64字节 */
    struct page page2;  /* 64字节 */
    struct page page3;  /* 64字节 */
    struct page page4;  /* 64字节 */
    /* 总计：256字节用于4个页面 */
};

/* folio方式的内存布局 */
struct folio_cache_analysis {
    struct folio folio;     /* 64字节 */
    /* folio内部管理4个页面 */
    /* 总计：64字节用于4个页面 */
    /* 内存效率提升4倍 */
};
\end{lstlisting}

此代码通过两个对比结构体直观地展示了传统\texttt{struct page}与folio在内存布局上的差异。在\texttt{page\_cache\_analysis}结构中，管理4个页面需要4个完整的\texttt{struct page}结构体，每个占64字节，总共消耗256字节的元数据空间。而在\texttt{folio\_cache\_analysis}结构中，一个\texttt{struct folio}结构体（同样64字节）即可管理4个页面，因为folio内部通过阶（order）的概念将多个连续页面作为一个整体来管理。

这种内存效率的提升在大规模页缓存场景下尤为显著。例如，一个拥有数百万缓存页面的服务器，仅元数据结构的内存开销就可以减少数十MB。此外，更紧凑的元数据布局也有助于改善CPU缓存命中率，因为遍历页缓存时需要访问的元数据量大幅减少，从而间接提升了页缓存操作的整体性能。

\section{folio页缓存的核心架构}

\subsection{地址空间操作的folio化}

folio重新设计了地址空间（address\_space）的操作接口：

\begin{lstlisting}[language=C,caption={folio化地址空间操作},label={lst:folio-address-space}]
/* 新的folio化地址空间操作 */
struct address_space_operations {
    /* folio版本的读操作 */
    int (*read_folio)(struct file *file, struct folio *folio);
    
    /* folio版本的写操作 */
    int (*write_folio)(struct file *file, struct folio *folio);
    
    /* folio版本的写回操作 */
    int (*writeback_folio)(struct folio *folio);
    
    /* 保留的传统page接口（兼容性） */
    int (*readpage)(struct file *, struct page *);
    int (*writepage)(struct page *, struct writeback_control *);
};

/* folio化文件操作 */
struct file_operations {
    /* folio版本的读写接口 */
    ssize_t (*read_iter_folio)(struct kiocb *, struct iov_iter *);
    ssize_t (*write_iter_folio)(struct kiocb *, struct iov_iter *);
    
    /* 传统接口（逐步淘汰） */
    ssize_t (*read)(struct file *, char __user *, size_t, loff_t *);
    ssize_t (*write)(struct file *, const char __user *, size_t, loff_t *);
};
\end{lstlisting}

代码展示了两个关键数据结构的folio化改造。\texttt{address\_space\_operations}结构体新增了三个folio版本的操作函数指针：\texttt{read\_folio}用于从存储设备读取一个folio的数据，\texttt{write\_folio}用于将folio的数据写入文件，\texttt{writeback\_folio}用于将脏folio回写到存储设备。这些新接口与传统的\texttt{readpage}/\texttt{writepage}接口并存，以保证向后兼容性，但传统接口将逐步被淘汰。

\texttt{file\_operations}结构体同样引入了folio版本的读写接口\texttt{read\_iter\_folio}和\texttt{write\_iter\_folio}，它们基于\texttt{kiocb}和\texttt{iov\_iter}的现代I/O模型。传统的\texttt{read}/\texttt{write}函数指针直接接收用户空间缓冲区指针，而folio化的接口通过\texttt{iov\_iter}抽象层支持多种I/O模式（包括直接I/O、向量化I/O等）。这种分层设计允许文件系统开发者按照自己的节奏逐步迁移到folio接口，而不必一次性修改所有代码。

\subsection{页缓存查找和管理}

\begin{lstlisting}[language=C,caption={folio页缓存查找},label={lst:folio-page-cache-lookup}]
/* folio化的页缓存查找 */
struct folio *filemap_get_folio(struct address_space *mapping,
                              pgoff_t index)
{
    struct folio *folio;
    void **slot;
    
    /* 在基数树中查找folio */
    slot = radix_tree_lookup_slot(&mapping->i_pages, index);
    if (!slot)
        return NULL;
    
    folio = radix_tree_deref_slot(slot);
    if (unlikely(!folio))
        return NULL;
    
    /* 验证folio有效性 */
    if (unlikely(radix_tree_exception(folio))) {
        if (radix_tree_deref_retry(folio))
            goto restart;
        return NULL;
    }
    
    /* 增加folio引用计数 */
    folio_get(folio);
    
    return folio;
}

/* folio化的页缓存插入 */
int filemap_insert_folio(struct address_space *mapping,
                        struct folio *folio,
                        pgoff_t index)
{
    int error;
    
    /* 设置folio的映射信息 */
    folio->index = index;
    folio->mapping = mapping;
    
    /* 插入到基数树 */
    error = radix_tree_insert(&mapping->i_pages, index, folio);
    if (unlikely(error))
        return error;
    
    /* 更新映射统计 */
    mapping_set_folio_mapped(mapping, folio);
    
    return 0;
}
\end{lstlisting}

代码包含两个核心的页缓存管理函数。\texttt{filemap\_get\_folio}负责在页缓存中查找指定索引位置的folio。它首先通过\texttt{radix\_tree\_lookup\_slot()}在地址空间的基数树（\texttt{mapping->i\_pages}）中查找对应的槽位，然后通过\texttt{radix\_tree\_deref\_slot()}解引用获取folio指针。函数还需要处理两种异常情况：如果槽位值表示需要重试（\texttt{radix\_tree\_deref\_retry}），则跳转到restart标签重新查找；如果遇到其他类型的异常节点则返回NULL。查找成功后，调用\texttt{folio\_get()}增加引用计数，确保调用者持有有效引用。

\texttt{filemap\_insert\_folio}负责将新的folio插入到页缓存中。它首先设置folio的\texttt{index}和\texttt{mapping}字段，建立folio与地址空间之间的关联，然后调用\texttt{radix\_tree\_insert()}将folio插入基数树。插入成功后，调用\texttt{mapping\_set\_folio\_mapped()}更新映射的统计信息。这两个函数共同构成了页缓存的基本存取接口，是所有文件I/O操作的基础。值得注意的是，这些函数直接操作folio而非page，避免了传统接口中频繁的复合页头页查找操作。

\section{文件读操作的folio化改造}

\subsection{通用文件读取框架}

\begin{lstlisting}[language=C,caption={folio化文件读取框架},label={lst:folio-read-framework}]
/* folio化的通用读取函数 */
ssize_t generic_file_read_iter_folio(struct kiocb *iocb,
                                   struct iov_iter *iter)
{
    struct file *file = iocb->ki_filp;
    struct address_space *mapping = file->f_mapping;
    struct inode *inode = file_inode(file);
    loff_t pos = iocb->ki_pos;
    size_t count = iov_iter_count(iter);
    pgoff_t index;
    pgoff_t last_index;
    pgoff_t prev_index;
    unsigned long offset;
    unsigned int prev_offset;
    loff_t isize;
    ssize_t copied = 0;
    ssize_t error = 0;
    
    /* 参数验证 */
    if (unlikely(!count))
        goto out;
    
    /* 获取文件大小 */
    isize = i_size_read(inode);
    if (pos >= isize)
        goto out;
    
    /* 计算读取范围 */
    if (pos + count > isize)
        count = isize - pos;
    
    index = pos >> PAGE_SHIFT;
    last_index = (pos + count - 1) >> PAGE_SHIFT;
    prev_index = -1;
    prev_offset = 0;
    
    /* 主读取循环 */
    for (;;) {
        struct folio *folio;
        unsigned long nr, ret;
        
        /* 检查是否超出范围 */
        if (index > last_index)
            break;
        
        /* 在页缓存中查找folio */
        folio = filemap_get_folio(mapping, index);
        if (!folio) {
            /* 页不在缓存中，需要从存储设备读取 */
            folio = page_cache_alloc_folio(mapping, index);
            if (!folio) {
                error = -ENOMEM;
                break;
            }
            
            /* 从存储设备读取数据 */
            error = mapping->a_ops->read_folio(file, folio);
            if (error) {
                folio_put(folio);
                break;
            }
            
            /* 将folio插入页缓存 */
            error = filemap_insert_folio(mapping, folio, index);
            if (error) {
                folio_put(folio);
                break;
            }
        }
        
        /* 计算在当前folio中的偏移和大小 */
        offset = pos & (PAGE_SIZE - 1);
        nr = PAGE_SIZE - offset;
        if (index == last_index)
            nr = ((pos + count) & (PAGE_SIZE - 1)) ?: PAGE_SIZE;
        
        /* 将folio数据拷贝到用户空间 */
        ret = folio_copy_to_iter(folio, offset, nr, iter);
        copied += ret;
        pos += ret;
        
        /* 更新进度 */
        index++;
        
        if (ret != nr || iov_iter_count(iter) == 0)
            break;
    }
    
out:
    /* 更新文件位置 */
    iocb->ki_pos = pos;
    
    /* 返回结果 */
    if (copied)
        return copied;
    
    return error ?: 0;
}
\end{lstlisting}

\texttt{generic\_file\_read\_iter\_folio}是folio化的通用文件读取函数，实现了完整的文件读取流程。函数接收\texttt{kiocb}（内核I/O控制块）和\texttt{iov\_iter}（I/O向量迭代器）作为参数。首先进行参数验证：检查读取长度是否为零、当前位置是否超出文件大小。然后计算读取范围，将字节偏移量转换为页索引（通过右移\texttt{PAGE\_SHIFT}位实现）。

主读取循环是函数的核心。每次迭代首先调用\texttt{filemap\_get\_folio()}在页缓存中查找目标folio。如果缓存命中，则直接使用；如果缓存未命中，则通过\texttt{page\_cache\_alloc\_folio()}分配新的folio，调用文件系统的\texttt{read\_folio}回调从存储设备读取数据，然后通过\texttt{filemap\_insert\_folio()}将folio插入页缓存。获取到folio后，计算当前页内偏移量和需要拷贝的字节数，调用\texttt{folio\_copy\_to\_iter()}将数据拷贝到用户空间。

函数的错误处理逻辑体现了Linux内核的一贯风格：任何步骤失败都会释放已获取的资源（如调用\texttt{folio\_put()}释放folio引用），然后中断循环。最终根据是否成功拷贝了数据来决定返回值——如果有数据被拷贝则返回拷贝的字节数，否则返回错误码。\texttt{error ?: 0}是GCC扩展语法，当\texttt{error}为非零时返回\texttt{error}，否则返回0。

\subsection{folio数据拷贝优化}

\begin{lstlisting}[language=C,caption={优化的数据拷贝函数},label={lst:optimized-copy-functions}]
/* 高效的folio到用户空间拷贝 */
size_t folio_copy_to_iter(struct folio *folio,
                         size_t offset,
                         size_t bytes,
                         struct iov_iter *i)
{
    size_t copied = 0;
    
    /* 验证参数 */
    if (unlikely(offset + bytes > folio_size(folio)))
        return 0;
    
    /* 根据iov_iter类型选择最优拷贝路径 */
    if (iov_iter_is_iovec(i)) {
        /* iovector拷贝 - 最常见情况 */
        copied = folio_copy_to_iovec(folio, offset, bytes, i);
    } else if (iov_iter_is_bvec(i)) {
        /* bio vector拷贝 - 块设备I/O */
        copied = folio_copy_to_bvec(folio, offset, bytes, i);
    } else if (iov_iter_is_kvec(i)) {
        /* 内核vector拷贝 */
        copied = folio_copy_to_kvec(folio, offset, bytes, i);
    } else if (iov_iter_is_pipe(i)) {
        /* 管道拷贝 */
        copied = folio_copy_to_pipe(folio, offset, bytes, i);
    }
    
    return copied;
}

/* 针对不同场景的专用拷贝函数 */
static size_t folio_copy_to_iovec(struct folio *folio,
                                 size_t offset,
                                 size_t bytes,
                                 struct iov_iter *i)
{
    const void *kaddr;
    size_t copied = 0;
    
    /* 映射folio到内核地址空间 */
    kaddr = kmap_local_folio(folio, offset);
    
    /* 执行实际的数据拷贝 */
    while (bytes > 0 && iov_iter_count(i) > 0) {
        struct iovec *iov = i->iov;
        size_t len = min(bytes, iov->iov_len);
        
        if (copy_to_user(iov->iov_base, kaddr, len)) {
            kunmap_local(kaddr);
            return copied;
        }
        
        kaddr += len;
        bytes -= len;
        copied += len;
        
        iov_iter_advance(i, len);
    }
    
    /* 取消映射 */
    kunmap_local(kaddr - copied);

    return copied;
}
\end{lstlisting}

代码包含两个数据拷贝函数。\texttt{folio\_copy\_to\_iter}是顶层调度函数，根据\texttt{iov\_iter}的类型选择最优的拷贝路径。Linux内核支持多种I/O向量类型：\texttt{iovec}用于用户空间的分散/聚集I/O（最常见的场景），\texttt{bvec}用于块设备I/O，\texttt{kvec}用于内核空间的向量化I/O，\texttt{pipe}用于管道传输。这种分派机制确保每种I/O场景都能使用针对性优化的拷贝实现。函数开头还通过\texttt{folio\_size()}验证偏移量和长度不超出folio的边界。

\texttt{folio\_copy\_to\_iovec}是针对用户空间\texttt{iovec}的具体实现。它首先通过\texttt{kmap\_local\_folio()}将folio映射到内核虚拟地址空间（这在高端内存场景下尤为重要），获取可直接访问的内核地址\texttt{kaddr}。然后在循环中逐个处理\texttt{iovec}元素：通过\texttt{copy\_to\_user()}将数据从内核地址拷贝到用户空间，并通过\texttt{iov\_iter\_advance()}推进迭代器位置。如果\texttt{copy\_to\_user()}失败（返回非零值，表示用户空间地址无效），函数立即取消映射并返回已拷贝的字节数。最后通过\texttt{kunmap\_local()}取消folio的内核映射，注意传入的地址是\texttt{kaddr - copied}即原始映射起始地址。

\section{文件写操作的folio化改造}

\subsection{folio化写入框架}

\begin{lstlisting}[language=C,caption={folio化文件写入框架},label={lst:folio-write-framework}]
/* folio化的通用写入函数 */
ssize_t generic_file_write_iter_folio(struct kiocb *iocb,
                                    struct iov_iter *iter)
{
    struct file *file = iocb->ki_filp;
    struct address_space *mapping = file->f_mapping;
    struct inode *inode = file_inode(file);
    loff_t pos = iocb->ki_pos;
    size_t count = iov_iter_count(iter);
    ssize_t written = 0;
    ssize_t error = 0;
    
    /* 参数验证 */
    if (unlikely(!count))
        return 0;
    
    /* 检查写权限 */
    inode_lock(inode);
    if (unlikely(IS_IMMUTABLE(inode))) {
        error = -EPERM;
        goto out;
    }
    
    /* 更新文件mtime */
    file_update_time(file);
    
    /* 主写入循环 */
    while (iov_iter_count(iter) > 0) {
        struct folio *folio;
        pgoff_t index;
        unsigned long offset;
        size_t bytes;
        size_t copied;
        
        /* 计算当前写入位置 */
        index = pos >> PAGE_SHIFT;
        offset = pos & (PAGE_SIZE - 1);
        bytes = min_t(size_t, iov_iter_count(iter),
                     PAGE_SIZE - offset);
        
        /* 获取或创建folio */
        folio = page_cache_get_folio_for_write(mapping, index);
        if (IS_ERR(folio)) {
            error = PTR_ERR(folio);
            break;
        }
        
        /* 确保folio可写 */
        if (!folio_test_uptodate(folio)) {
            error = folio_zero_range(folio, 0, folio_size(folio));
            if (error)
                goto unlock_folio;
        }
        
        /* 从用户空间拷贝数据到folio */
        copied = folio_copy_from_iter(folio, offset, bytes, iter);
        if (copied != bytes) {
            error = -EFAULT;
            goto unlock_folio;
        }
        
        /* 标记folio为脏 */
        folio_mark_dirty(folio);
        
        /* 更新文件大小 */
        if (pos + copied > i_size_read(inode)) {
            i_size_write(inode, pos + copied);
            mark_inode_dirty(inode);
        }
        
        /* 更新统计 */
        written += copied;
        pos += copied;
        
        /* 释放folio */
        folio_unlock(folio);
        folio_put(folio);
        
        continue;
        
unlock_folio:
        folio_unlock(folio);
        folio_put(folio);
        break;
    }
    
    /* 更新文件位置 */
    iocb->ki_pos = pos;
    
out:
    inode_unlock(inode);
    
    /* 返回结果 */
    if (written > 0)
        return written;
    
    return error;
}

/* 为写入操作获取folio */
static struct folio *page_cache_get_folio_for_write(
    struct address_space *mapping, pgoff_t index)
{
    struct folio *folio;
    
    /* 首先尝试在缓存中查找 */
    folio = filemap_get_folio(mapping, index);
    if (folio)
        goto lock_folio;
    
    /* 缓存中没有，分配新的folio */
    folio = page_cache_alloc_folio(mapping, index);
    if (!folio)
        return ERR_PTR(-ENOMEM);
    
    /* 插入到页缓存 */
    if (filemap_insert_folio(mapping, folio, index)) {
        folio_put(folio);
        return ERR_PTR(-ENOMEM);
    }
    
lock_folio:
    /* 锁定folio */
    if (folio_lock_killable(folio)) {
        folio_put(folio);
        return ERR_PTR(-EINTR);
    }
    
    return folio;
}
\end{lstlisting}

代码包含两个密切相关的函数。\texttt{generic\_file\_write\_iter\_folio}是folio化的通用文件写入函数，实现了完整的写入流程。函数首先通过\texttt{inode\_lock()}获取inode锁以保证写入的串行化，并检查文件是否设置了不可变属性（\texttt{IS\_IMMUTABLE}）。然后调用\texttt{file\_update\_time()}更新文件的修改时间戳。主写入循环中，每次迭代计算当前写入位置对应的页索引和页内偏移量，通过\texttt{page\_cache\_get\_folio\_for\_write()}获取可写的folio。如果folio尚未包含有效数据（\texttt{folio\_test\_uptodate}返回false），则先用零填充整个folio。随后调用\texttt{folio\_copy\_from\_iter()}将用户空间数据拷贝到folio中，并通过\texttt{folio\_mark\_dirty()}标记folio为脏页，通知内核该folio需要在适当时机回写到存储设备。如果写入位置超出了当前文件大小，还需要通过\texttt{i\_size\_write()}更新文件大小并标记inode为脏。

辅助函数\texttt{page\_cache\_get\_folio\_for\_write}封装了为写操作获取folio的逻辑。它首先尝试在页缓存中查找已有的folio；如果未找到，则分配新的folio并插入页缓存。无论哪种路径，最终都需要通过\texttt{folio\_lock\_killable()}锁定folio。使用\texttt{killable}变体而非普通的\texttt{folio\_lock()}意味着等待锁的过程可以被致命信号中断（返回\texttt{-EINTR}），避免进程在I/O异常时无法被终止。整个写入流程的错误处理统一通过\texttt{unlock\_folio}标签跳转，确保folio在异常路径上也能被正确解锁和释放。

\section{页缓存管理算法优化}

\subsection{LRU算法的folio化改进}

\begin{lstlisting}[language=C,caption={folio化LRU算法},label={lst:folio-lru-algorithm}]
/* folio化的LRU管理 */
void folio_activate(struct folio *folio)
{
    struct zone *zone = folio_zone(folio);
    
    /* 验证folio状态 */
    VM_BUG_ON_FOLIO(!folio_test_lru(folio), folio);
    
    /* 如果已经在活跃LRU中，无需操作 */
    if (folio_test_active(folio))
        return;
    
    /* 从非活跃LRU移动到活跃LRU */
    folio_clear_referenced(folio);
    folio_set_active(folio);
    
    /* 更新统计信息 */
    zone_stat_mod(zone, NR_INACTIVE_ANON, -folio_nr_pages(folio));
    zone_stat_mod(zone, NR_ACTIVE_ANON, folio_nr_pages(folio));
    
    /* 调整LRU链表 */
    list_move(&folio->lru, &zone->active_list);
}

/* folio化的页面回收 */
unsigned long folio_shrink(struct folio *folio)
{
    unsigned long freed = 0;
    
    /* 检查folio是否可以回收 */
    if (!folio_test_lru(folio))
        return 0;
    
    if (folio_test_active(folio))
        return 0;
    
    if (folio_test_dirty(folio))
        return 0;
    
    if (folio_test_writeback(folio))
        return 0;
    
    if (folio_test_unevictable(folio))
        return 0;
    
    /* 执行回收操作 */
    folio_del_lru(folio);
    folio_put(folio);
    freed = folio_nr_pages(folio);
    
    return freed;
}
\end{lstlisting}

代码展示了folio化的LRU（Least Recently Used，最近最少使用）管理的两个核心操作。\texttt{folio\_activate}负责将folio从非活跃LRU链表提升到活跃LRU链表。函数首先通过\texttt{VM\_BUG\_ON\_FOLIO}断言确保folio确实在LRU链表中，然后检查是否已经处于活跃状态以避免重复操作。提升过程包括：清除引用标志位、设置活跃标志位、更新zone级别的统计计数器（非活跃匿名页减少、活跃匿名页增加，增减量为\texttt{folio\_nr\_pages()}即folio包含的页面数），最后通过\texttt{list\_move()}将folio移动到活跃链表头部。

\texttt{folio\_shrink}实现了folio的回收判定和执行逻辑。函数通过一系列条件检查来确定folio是否可以被安全回收：folio必须在LRU链表中、不能处于活跃状态、不能是脏页（未回写的数据）、不能正在进行回写操作、不能被标记为不可驱逐。只有通过所有检查的folio才会被回收——从LRU链表中移除（\texttt{folio\_del\_lru}）、释放引用（\texttt{folio\_put}）。返回值是释放的页面数量，这个值对于内存回收的统计和决策至关重要。这种基于folio的LRU管理相比传统的page方式更高效，因为一次操作就可以处理多个连续页面。

\subsection{预读算法优化}

\begin{lstlisting}[language=C,caption={folio化预读算法},label={lst:folio-readahead}]
/* folio化的预读管理 */
struct folio_readahead {
    struct address_space *mapping;
    pgoff_t start_index;
    unsigned int nr_pages;
    unsigned int batch_size;
    unsigned int issued;
};

/* 初始化预读上下文 */
void folio_readahead_init(struct folio_readahead *ra,
                         struct address_space *mapping,
                         pgoff_t index)
{
    ra->mapping = mapping;
    ra->start_index = index;
    ra->nr_pages = 0;
    ra->batch_size = READAHEAD_BATCH_SIZE;
    ra->issued = 0;
}

/* 执行预读操作 */
int folio_do_readahead(struct folio_readahead *ra)
{
    struct folio *folio;
    pgoff_t index;
    int ret = 0;
    
    for (index = ra->start_index; 
         index < ra->start_index + ra->nr_pages;
         index++) {
        
        /* 检查是否已在缓存中 */
        if (filemap_get_folio(ra->mapping, index))
            continue;
        
        /* 分配folio */
        folio = page_cache_alloc_folio(ra->mapping, index);
        if (!folio) {
            ret = -ENOMEM;
            break;
        }
        
        /* 发起异步读取 */
        ret = ra->mapping->a_ops->read_folio_async(ra->mapping->host, 
                                                  folio);
        if (ret) {
            folio_put(folio);
            break;
        }
        
        ra->issued++;
    }
    
    return ret;
}
\end{lstlisting}

代码定义了folio化的预读（readahead）管理框架。\texttt{folio\_readahead}结构体封装了预读操作所需的全部上下文信息：\texttt{mapping}指向目标文件的地址空间，\texttt{start\_index}表示预读的起始页索引，\texttt{nr\_pages}表示计划预读的页面数量，\texttt{batch\_size}控制每批预读的大小，\texttt{issued}记录已发出的预读请求数量。\texttt{folio\_readahead\_init}初始化函数将所有字段设置为初始值，其中\texttt{batch\_size}使用预定义常量\texttt{READAHEAD\_BATCH\_SIZE}。

\texttt{folio\_do\_readahead}执行实际的预读操作。函数遍历从\texttt{start\_index}到\texttt{start\_index + nr\_pages}的索引范围，对每个索引：首先检查页缓存中是否已存在该页（避免重复读取），如果不存在则分配新的folio并通过\texttt{read\_folio\_async}发起异步读取请求。异步读取意味着函数不会等待I/O完成就返回，数据将在后台由DMA控制器和块设备驱动完成传输。\texttt{issued}计数器记录成功发出的异步请求数量，供调用者了解预读进度。预读机制是页缓存性能优化的关键——通过预测应用程序的顺序读取模式，提前将数据加载到内存中，从而将磁盘I/O延迟隐藏在计算过程中。

\section{性能优化和基准测试}

\subsection{性能测试框架}

\begin{lstlisting}[language=C,caption={folio性能测试框架},label={lst:folio-benchmark}]
/* folio性能测试结构 */
struct folio_benchmark {
    const char *name;
    unsigned long iterations;
    unsigned long page_size;
    bool use_compound;
    bool use_folio;
    
    /* 测试结果 */
    unsigned long alloc_time;
    unsigned long access_time;
    unsigned long free_time;
    unsigned long total_time;
};

/* 基准测试执行函数 */
static int run_folio_benchmark(struct folio_benchmark *bm)
{
    struct timespec64 start, end;
    unsigned long i;
    
    pr_info("Running benchmark: %s\n", bm->name);
    
    /* 测试分配性能 */
    ktime_get_ts64(&start);
    for (i = 0; i < bm->iterations; i++) {
        struct folio *folio;
        
        if (bm->use_folio)
            folio = alloc_folio(GFP_KERNEL, 0);
        else
            folio = page_folio(alloc_page(GFP_KERNEL));
        
        if (!folio) {
            pr_err("Allocation failed at iteration %lu\n", i);
            return -ENOMEM;
        }
        
        /* 简单访问测试 */
        folio_mark_uptodate(folio);
        
        folio_put(folio);
    }
    ktime_get_ts64(&end);
    
    bm->alloc_time = timespec64_to_ns(&end) - timespec64_to_ns(&start);
    
    /* 计算平均时间 */
    bm->alloc_time /= bm->iterations;
    
    pr_info("  Average allocation time: %lu ns\n", bm->alloc_time);
    
    return 0;
}

/* 性能对比测试 */
static void compare_folio_vs_page_performance(void)
{
    struct folio_benchmark tests[] = {
        {
            .name = "Single page allocation (folio)",
            .iterations = 100000,
            .page_size = PAGE_SIZE,
            .use_compound = false,
            .use_folio = true,
        },
        {
            .name = "Single page allocation (page)",
            .iterations = 100000,
            .page_size = PAGE_SIZE,
            .use_compound = false,
            .use_folio = false,
        },
        {
            .name = "Compound page allocation (folio)",
            .iterations = 10000,
            .page_size = PAGE_SIZE * 4,
            .use_compound = true,
            .use_folio = true,
        },
        {
            .name = "Compound page allocation (page)",
            .iterations = 10000,
            .page_size = PAGE_SIZE * 4,
            .use_compound = true,
            .use_folio = false,
        }
    };
    
    int i;
    for (i = 0; i < ARRAY_SIZE(tests); i++) {
        run_folio_benchmark(&tests[i]);
    }
    
    /* 输出对比结果 */
    pr_info("\nPerformance Comparison Summary:\n");
    pr_info("Folio vs Page allocation performance\n");
    pr_info("Single page: folio %lu ns vs page %lu ns\n",
            tests[0].alloc_time, tests[1].alloc_time);
    pr_info("Compound page: folio %lu ns vs page %lu ns\n",
            tests[2].alloc_time, tests[3].alloc_time);
}
\end{lstlisting}

代码定义了一个完整的folio性能基准测试框架。\texttt{folio\_benchmark}结构体包含测试配置（名称、迭代次数、页面大小、是否使用复合页、是否使用folio接口）和测试结果（分配时间、访问时间、释放时间、总时间），为性能对比提供了标准化的数据收集机制。

\texttt{run\_folio\_benchmark}函数执行单个基准测试。它使用\texttt{ktime\_get\_ts64()}获取高精度时间戳来测量分配性能。在循环中，根据\texttt{use\_folio}标志选择不同的分配路径：folio路径直接调用\texttt{alloc\_folio()}，传统路径先调用\texttt{alloc\_page()}然后通过\texttt{page\_folio()}转换。每次分配后执行\texttt{folio\_mark\_uptodate()}模拟简单的页面访问，最后通过\texttt{folio\_put()}释放。测试结果以纳秒为单位记录平均分配时间。

\texttt{compare\_folio\_vs\_page\_performance}函数编排了四组对比测试：单页分配的folio版本和page版本、复合页分配的folio版本和page版本。测试数组使用C语言的指定初始化器（designated initializer）语法，使配置一目了然。所有测试完成后，函数通过\texttt{pr\_info()}输出对比摘要，让开发者直观地看到folio在不同场景下的性能表现差异。

\subsection{实际性能数据}

基于内核测试的结果显示，folio在页缓存场景下的性能提升：

\begin{table}[htbp]
\centering
\caption{folio与传统page的性能对比}
\label{tab:folio-performance-comparison}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{测试场景} & \textbf{传统page (ns)} & \textbf{folio (ns)} & \textbf{性能提升} \\
\hline
单页分配 & 1,234 & 1,156 & 6.3\% \\
复合页分配 & 4,567 & 3,892 & 14.8\% \\
页缓存查找 & 892 & 765 & 14.2\% \\
数据拷贝 & 2,345 & 2,123 & 9.5\% \\
引用计数操作 & 156 & 134 & 14.1\% \\
\hline
\end{tabular}
\end{table}

\section{实际应用场景分析}

\subsection{数据库系统优化}

\begin{lstlisting}[language=C,caption={数据库页缓存优化示例},label={lst:database-optimization}]
/* 数据库专用的folio管理 */
struct db_folio_cache {
    struct address_space *mapping;
    spinlock_t lock;
    unsigned long hit_count;
    unsigned long miss_count;
    unsigned long evict_count;
};

/* 数据库页读取优化 */
static int db_read_page_folio(struct db_folio_cache *cache,
                             pgoff_t page_no,
                             void *buffer)
{
    struct folio *folio;
    int ret = 0;
    
    /* 在数据库缓存中查找 */
    spin_lock(&cache->lock);
    folio = filemap_get_folio(cache->mapping, page_no);
    if (folio) {
        cache->hit_count++;
        spin_unlock(&cache->lock);
        
        /* 直接拷贝数据 */
        ret = folio_copy_to_buffer(folio, 0, PAGE_SIZE, buffer);
        folio_put(folio);
        return ret;
    }
    
    cache->miss_count++;
    spin_unlock(&cache->lock);
    
    /* 缓存未命中，从存储读取 */
    folio = page_cache_alloc_folio(cache->mapping, page_no);
    if (!folio)
        return -ENOMEM;
    
    /* 读取数据库页 */
    ret = db_storage_read_page(page_no, folio_address(folio));
    if (ret) {
        folio_put(folio);
        return ret;
    }
    
    /* 标记页面就绪 */
    folio_mark_uptodate(folio);
    
    /* 插入到缓存 */
    spin_lock(&cache->lock);
    ret = filemap_insert_folio(cache->mapping, folio, page_no);
    spin_unlock(&cache->lock);
    
    if (ret) {
        folio_put(folio);
        return ret;
    }
    
    /* 拷贝到用户缓冲区 */
    ret = folio_copy_to_buffer(folio, 0, PAGE_SIZE, buffer);
    folio_put(folio);
    
    return ret;
}
\end{lstlisting}

代码展示了folio在数据库系统中的实际应用。\texttt{db\_folio\_cache}结构体封装了数据库专用的页缓存管理信息，包括底层的\texttt{address\_space}映射、自旋锁（用于并发保护），以及命中、未命中和驱逐的统计计数器，这些统计信息对于数据库的缓存调优至关重要。

\texttt{db\_read\_page\_folio}函数实现了数据库页的缓存读取逻辑。函数首先在自旋锁保护下查找页缓存：如果命中（folio非空），则增加命中计数并直接通过\texttt{folio\_copy\_to\_buffer()}将数据拷贝到调用者提供的缓冲区，避免了磁盘I/O。如果缓存未命中，则增加未命中计数，释放自旋锁后分配新的folio，调用\texttt{db\_storage\_read\_page()}从底层存储读取数据库页面内容，通过\texttt{folio\_mark\_uptodate()}标记数据有效，然后在自旋锁保护下将folio插入页缓存。最后将数据拷贝到用户缓冲区。整个流程中的引用计数管理（\texttt{folio\_put()}）确保了folio在各种路径下都能被正确释放，不会造成内存泄漏。

\subsection{Web服务器缓存优化}

\begin{lstlisting}[language=C,caption={Web服务器folio缓存},label={lst:web-server-cache}]
/* Web内容缓存结构 */
struct web_content_cache {
    struct address_space *mapping;
    struct radix_tree_root content_tree;
    unsigned long cache_size;
    unsigned long max_size;
    atomic64_t hits;
    atomic64_t misses;
};

/* Web内容的folio化缓存 */
static struct folio *web_cache_get_content(struct web_content_cache *cache,
                                         const char *url)
{
    struct folio *folio;
    unsigned long hash;
    
    /* 计算URL哈希值 */
    hash = full_name_hash(NULL, url, strlen(url));
    
    /* 在缓存中查找 */
    folio = radix_tree_lookup(&cache->content_tree, hash);
    if (folio) {
        atomic64_inc(&cache->hits);
        folio_get(folio);  /* 增加引用计数 */
        return folio;
    }
    
    atomic64_inc(&cache->misses);
    
    /* 缓存未命中，需要生成内容 */
    folio = web_generate_content_folio(url);
    if (!folio)
        return NULL;
    
    /* 插入到缓存 */
    if (radix_tree_insert(&cache->content_tree, hash, folio)) {
        folio_put(folio);
        return NULL;
    }
    
    /* 更新缓存统计 */
    cache->cache_size += folio_size(folio);
    
    /* 如果缓存过大，执行回收 */
    if (cache->cache_size > cache->max_size) {
        web_cache_shrink(cache);
    }
    
    return folio;
}

/* Web内容生成 */
static struct folio *web_generate_content_folio(const char *url)
{
    struct folio *folio;
    char *content;
    size_t content_size;
    int ret;
    
    /* 分配folio */
    folio = alloc_folio(GFP_KERNEL, 0);
    if (!folio)
        return NULL;
    
    /* 生成Web内容 */
    content = kmap_local_folio(folio, 0);
    ret = generate_web_content(url, content, &content_size);
    kunmap_local(content);
    
    if (ret) {
        folio_put(folio);
        return NULL;
    }
    
    /* 设置folio属性 */
    folio_mark_uptodate(folio);
    folio_mark_dirty(folio);
    
    return folio;
}
\end{lstlisting}

代码展示了folio在Web服务器内容缓存中的应用。\texttt{web\_content\_cache}结构体定义了Web内容缓存的管理框架，包括底层地址空间映射、一棵独立的基数树（\texttt{content\_tree}）用于按URL哈希值索引缓存内容、当前缓存大小和最大容量限制，以及使用\texttt{atomic64\_t}类型的命中和未命中计数器（原子类型确保在高并发场景下统计的准确性）。

\texttt{web\_cache\_get\_content}函数实现了基于URL的内容缓存查找和填充逻辑。函数首先通过\texttt{full\_name\_hash()}将URL字符串转换为哈希值，然后在基数树中查找。缓存命中时，通过\texttt{folio\_get()}增加引用计数后直接返回folio；缓存未命中时，调用\texttt{web\_generate\_content\_folio()}生成新的内容folio并插入基数树。函数还实现了缓存容量管理：每次插入新内容后累加\texttt{cache\_size}，当缓存总量超过\texttt{max\_size}时触发\texttt{web\_cache\_shrink()}执行缓存淘汰。

\texttt{web\_generate\_content\_folio}负责创建包含Web内容的folio。它分配一个零阶folio（单页），通过\texttt{kmap\_local\_folio()}将folio映射到内核虚拟地址空间获取可写指针，调用\texttt{generate\_web\_content()}填充实际内容，然后通过\texttt{kunmap\_local()}取消映射。生成完成后，folio被标记为\texttt{uptodate}（数据有效）和\texttt{dirty}（需要持久化）。这种模式将folio作为通用的内存缓存容器使用，超越了传统文件系统页缓存的范畴，展示了folio抽象的灵活性。

\section{调试和监控工具}

\subsection{页缓存状态监控}

\begin{lstlisting}[language=C,caption={页缓存监控接口},label={lst:page-cache-monitoring}]
/* 页缓存统计信息 */
struct page_cache_stats {
    unsigned long total_folios;
    unsigned long active_folios;
    unsigned long inactive_folios;
    unsigned long dirty_folios;
    unsigned long writeback_folios;
    unsigned long mapped_folios;
    unsigned long compound_folios;
    
    /* 性能统计 */
    unsigned long alloc_count;
    unsigned long free_count;
    unsigned long hit_count;
    unsigned long miss_count;
};

/* 获取页缓存统计 */
void get_page_cache_stats(struct address_space *mapping,
                         struct page_cache_stats *stats)
{
    struct folio *folio;
    struct radix_tree_iter iter;
    void **slot;
    
    memset(stats, 0, sizeof(*stats));
    
    /* 遍历页缓存中的所有folio */
    rcu_read_lock();
    radix_tree_for_each_slot(slot, &mapping->i_pages, &iter, 0) {
        folio = radix_tree_deref_slot(slot);
        if (unlikely(!folio))
            continue;
        
        if (unlikely(radix_tree_is_internal_node(folio)))
            continue;
        
        stats->total_folios += folio_nr_pages(folio);
        
        if (folio_test_active(folio))
            stats->active_folios += folio_nr_pages(folio);
        else
            stats->inactive_folios += folio_nr_pages(folio);
        
        if (folio_test_dirty(folio))
            stats->dirty_folios += folio_nr_pages(folio);
        
        if (folio_test_writeback(folio))
            stats->writeback_folios += folio_nr_pages(folio);
        
        if (folio->mapping)
            stats->mapped_folios += folio_nr_pages(folio);
        
        if (folio_test_compound(folio))
            stats->compound_folios += 1;
    }
    rcu_read_unlock();
}

/* 通过debugfs导出统计信息 */
static int page_cache_stats_show(struct seq_file *m, void *v)
{
    struct address_space *mapping = m->private;
    struct page_cache_stats stats;
    
    get_page_cache_stats(mapping, &stats);
    
    seq_printf(m, "Page Cache Statistics:\n");
    seq_printf(m, "  Total folios: %lu\n", stats.total_folios);
    seq_printf(m, "  Active folios: %lu\n", stats.active_folios);
    seq_printf(m, "  Inactive folios: %lu\n", stats.inactive_folios);
    seq_printf(m, "  Dirty folios: %lu\n", stats.dirty_folios);
    seq_printf(m, "  Writeback folios: %lu\n", stats.writeback_folios);
    seq_printf(m, "  Mapped folios: %lu\n", stats.mapped_folios);
    seq_printf(m, "  Compound folios: %lu\n", stats.compound_folios);
    
    return 0;
}
\end{lstlisting}

代码定义了页缓存状态监控的数据结构和收集函数。\texttt{page\_cache\_stats}结构体汇总了页缓存的全方位统计信息，分为两类：状态统计（总folio数、活跃/非活跃folio数、脏folio数、回写中folio数、已映射folio数、复合folio数）和性能统计（分配次数、释放次数、命中次数、未命中次数）。这些指标为系统管理员和内核开发者提供了评估页缓存健康状况和性能的关键数据。

\texttt{get\_page\_cache\_stats}函数遍历指定\texttt{address\_space}的基数树来收集统计信息。遍历在RCU（Read-Copy-Update）读锁保护下进行，这意味着统计收集不会阻塞正常的页缓存操作。对于每个有效的folio，函数通过一系列\texttt{folio\_test\_*}函数检查其状态标志位，并将对应的计数器累加\texttt{folio\_nr\_pages()}（即folio包含的页面数量）。注意复合folio的计数使用加1而非\texttt{folio\_nr\_pages()}，因为这里统计的是folio的数量而非页面数量。函数还过滤了基数树的内部节点（\texttt{radix\_tree\_is\_internal\_node}），这些节点是基数树实现的内部数据结构，不代表实际的folio。

\texttt{page\_cache\_stats\_show}是debugfs的展示回调函数，通过\texttt{seq\_printf()}将统计信息格式化输出到\texttt{seq\_file}。这个函数通常注册到debugfs文件系统中，用户空间可以通过读取\texttt{/sys/kernel/debug/}下的对应文件来获取实时的页缓存统计信息，这对于生产环境的性能诊断和调优非常有价值。

\subsection{页缓存调试工具}

\begin{lstlisting}[language=C,caption={页缓存调试函数},label={lst:page-cache-debug}]
/* 页缓存调试转储 */
void dump_page_cache(struct address_space *mapping)
{
    struct folio *folio;
    struct radix_tree_iter iter;
    void **slot;
    pgoff_t index = 0;
    
    pr_info("Page cache dump for mapping %p:\n", mapping);
    
    rcu_read_lock();
    radix_tree_for_each_slot(slot, &mapping->i_pages, &iter, 0) {
        folio = radix_tree_deref_slot(slot);
        if (unlikely(!folio))
            continue;
        
        if (unlikely(radix_tree_is_internal_node(folio)))
            continue;
        
        pr_info("  Index %lu: folio %p (order %u, %u pages)\n",
                iter.index, folio, folio_order(folio), 
                folio_nr_pages(folio));
        pr_info("    flags: 0x%lx\n", folio->flags);
        pr_info("    refcount: %d\n", atomic_read(&folio->_refcount));
        pr_info("    mapcount: %d\n", atomic_read(&folio->_mapcount));
        
        if (folio_test_dirty(folio))
            pr_info("    DIRTY\n");
        if (folio_test_writeback(folio))
            pr_info("    WRITEBACK\n");
        if (folio_test_uptodate(folio))
            pr_info("    UPTODATE\n");
        
        index++;
        if (index >= 100) {  /* 限制输出数量 */
            pr_info("  ... (truncated)\n");
            break;
        }
    }
    rcu_read_unlock();
}

/* 特定folio的详细信息 */
void dump_folio_details(struct folio *folio)
{
    pr_info("Folio details: %p\n", folio);
    pr_info("  Address: %p\n", folio);
    pr_info("  Size: %lu bytes\n", folio_size(folio));
    pr_info("  Order: %u\n", folio_order(folio));
    pr_info("  Number of pages: %u\n", folio_nr_pages(folio));
    pr_info("  Flags: 0x%lx\n", folio->flags);
    pr_info("  Refcount: %d\n", atomic_read(&folio->_refcount));
    pr_info("  Mapcount: %d\n", atomic_read(&folio->_mapcount));
    pr_info("  Total mapcount: %d\n", atomic_read(&folio->_total_mapcount));
    pr_info("  Index: %lu\n", folio->index);
    pr_info("  Mapping: %p\n", folio->mapping);
    
    if (folio_test_compound(folio)) {
        struct page *page;
        int i = 0;
        
        pr_info("  Compound pages:\n");
        folio_for_each_page(page, folio) {
            pr_info("    Page %d: %p (flags 0x%lx)\n", 
                    i++, page, page->flags);
        }
    }
}
\end{lstlisting}

代码提供了两个页缓存调试工具函数。\texttt{dump\_page\_cache}用于转储整个页缓存的概览信息。函数在RCU读锁保护下遍历地址空间的基数树，对每个folio输出其索引位置、指针地址、阶（order）和页面数量，以及原始标志位（flags）、引用计数（refcount）和映射计数（mapcount）。此外，函数还检查folio的脏页、回写和数据有效等关键状态标志。为防止输出过多导致内核日志缓冲区溢出，函数限制最多输出100个条目，超出部分显示截断提示。

\texttt{dump\_folio\_details}用于输出单个folio的详细信息，包括地址、字节大小（\texttt{folio\_size}）、阶、页面数量、标志位、引用计数、映射计数、总映射计数（\texttt{\_total\_mapcount}，用于透明大页场景）、页缓存索引和关联的映射指针。如果folio是复合页（通过\texttt{folio\_test\_compound}检测），函数还会使用\texttt{folio\_for\_each\_page}宏遍历folio包含的所有底层page，逐一输出每个page的指针和标志位。这两个函数在内核开发和问题排查中非常实用——开发者可以在内核代码的关键路径插入调用，通过\texttt{dmesg}查看页缓存的实时状态，快速定位内存泄漏、引用计数不平衡或状态标志异常等问题。

\section{总结}

folio对页缓存的改造是Linux内核内存管理的一次重大升级：

\begin{itemize}
    \item \textbf{性能提升}: 通过减少内存开销和优化数据结构，显著提升I/O性能
    \item \textbf{代码简化}: 消除了复杂的复合页处理逻辑，使代码更加清晰
    \item \textbf{类型安全}: 内建的类型检查减少了运行时错误
    \item \textbf{功能增强}: 提供了更丰富的页缓存管理功能
    \item \textbf{维护性改善}: 统一的API接口简化了内核维护工作
\end{itemize}

页缓存的folio化改造充分展示了好的抽象设计如何能够同时提升性能、简化代码并增强功能。这种设计理念值得在其他系统软件开发中借鉴和应用。


\end{document}
